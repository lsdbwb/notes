# 指导思想
- 设计完备多线程程序不仅仅是掌握锁、条件变量、原子操作等基本操作就够了，还需要从更高层掌握多线程程序的设计思想
- 不仅要考虑线程的数量，线程间的任务分配等上层的设计，也要考虑底层的影响程序性能的细节

# 在线程间调配任务的技术
- 确保使用多线程为你的程序带来的收益（并发带来的性能提升）大于带来的损失（代码复杂度，潜在的race condiiton）
- 确定一个工作可以划分为多个互不相关的子任务
- 每个子任务选择**专门的线程**来完成，每个子任务使用的线程数量可以自行分配
- 是否需要专门的线程来做所有子任务的统筹安排
## 在线程间划分数据的方法
### 在程序开始之前就把数据划分好
- 如下图所示，在程序开始执行之前，将整块数据划分为多个chunk，每个chunk分给一个线程，线程间互不干扰
![[Pasted image 20220506113239.png]]
- 在所有的线程处理完后，可能需要聚合所有线程的结果，做一次reduce操作
- 要求：数据能够被清晰地划分且数据间没有关联，最终所需的结果能够由多个线程处理的结果聚合得到
### 运行时递归地划分数据
- 如下图所示，无法在程序运行开始前就把数据划分好，因为数据的划分和程序的运行状态有关
- 递归划分的每一部分的数据都是独立的，都可以用一个线程来处理
- 递归的深度过深时，使用的线程过多会影响性能，因此需要限制线程使用的数量
![[Pasted image 20220506114111.png]]
- 当限制了线程数量时，有些数据暂时得不到处理时可以先放到栈中，工作线程空闲后再去栈顶取数据处理

## 通过任务类型划分工作
- 在线程间划分数据的方法依赖于每个线程都完成**同样的工作**
- 实际上每个线程完成的任务可能是不同的
- 将整个系统划分为多个独立的小任务，每个任务指定一个线程来执行。线程间相对独立，只需要很少的交互
- 通过任务类型来划分，业务线程负责业务，系统后台线程负责系统的运行，监听线程负责监控系统的状态。（这些线程之间都会有交互，如果两个线程交互过于频繁，通信量太大，则要考虑任务划分的方法是否合适）

## 将一长串的任务划分为多个阶段
- 如果一个任务很长，可以划分为多个阶段，且每个阶段用到的数据是独立的
- 可以使用流水线模型(pipelines)
- 每个阶段都用一个或一组线程来完成，线程之间使用管道或者任务队列通信。前一个线程完成该阶段的事情后，将处理的结果放到队列，下一个线程从队列中取出数据接着处理

# 影响并发代码性能的因素
设计出的并发程序应该相比于单线程下有性能提升，不然毫无意义
## 处理器核心的数量
- 开发环境和实际部署生产环境的CPU数量，每个CPU的核心数量是不同的
- 因此需要根据实际环境设置合适的线程数量
- std::thread::hardware_concurrency()可以返回当前系统支持的最大线程数量。（只是一个提示，某些情况下不可信）
## data contention和cache ping-pong
在使用的线程数和CPU数量多了之后，多个处理器访问**共享数据**的可能性增大
- 在多个处理器**同时读**内存中的同一块数据时没有问题，每个处理器的缓存都有该内存数据的一份拷贝
- 如果有某个处理器要修改这个数据，则需要把缓存中修改过后的数据同步给其他处理器。（即缓存一致性，保证缓存一致性的cpu指令会很耗时）
- high data contention
	如果某个共享数据同时有多个处理器要访问并修改，其他处理器必须等待某个处理器修改该数据并执行完缓存同步操作后，才能继续执行
- cache ping-pong
	即在上述 high data contention的情况下，不停执行缓存同步的行为（缓存在多个处理器间不停同步）
- 使用mutex时，mutex就可以认为是共享数据，high data contention情况下也会出现上述问题
	mutex规定的是线程间在**操作系统层面**的同步（而不是处理器层面），如果某个线程在等待mutex，操作系统可以调度其他线程来使用CPU。但mutex也是共享数据，在多处理器对其进行同时访问操作时就会出现缓存一致性的问题

## false sharing
- 在多处理器同时访问一个内存位置的共享数据时要进行cache-line的同步，在high contention下会造成cache ping-pong问题
- 最好的解决方法就是尽量不使用共享数据
- 即使某个内存位置某时刻仅仅被一个线程访问，仍然可能出现cache ping-pong问题