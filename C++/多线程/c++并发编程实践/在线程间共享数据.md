
## 在线程间共享数据的问题
- 如果共享数据是read-only的，那么不存在问题
- 出现问题只发生在有线程想要修改共享数据的时候
- 出现问题时往往会破坏"一致性"(例如多线程同时修改一个共享的双向链表时，可能会破坏链表的结构，这就是破坏了一致性),会带来未定义的行为甚至程序崩溃
### Race conditions:
- 产生的原因：
	程序运行的结果和多个线程执行的顺序有关
- 性质：
	有些竞争条件是良性的，不会破坏一致性
	真正需要关注的是恶性的会破坏程序一致性的竞争条件
	可能造成未定义的行为
- 产生的时机
	竞争条件出现在某个线程**修改**某个数据时，由于cpu执行非常快速，出现竞争条件的时间窗口很小。
	只有恰好同时多个线程在时间窗口内修改了数据时，才可能会产生竞争条件
	竞争条件产生的bug往往是很难复现的
- 解决恶性race conditions的方法
 1. 对共享数据添加保护机制
	 比如锁，保证每次只能由一个线程处于修改共享数据的状态
 2. 修改数据结构的设计，使得每次修改数据都是原子操作，不同线程的执行顺序不会破坏一致性（无锁编程）
 3. 使用事务机制（类似于数据库中事务的处理）
	 事务操作每次将修改操作放到一个transaction log，然后一次性commit。commit时比较数据的状态是否一致。

### 在C++中使用锁保护共享变量
- *c++提供的锁：*
	**std::mutex**
	应该使用std::lock_guard来使用锁保护共享变量。std::lock_guard是RAII思想的实现，在构造函数中调用mutex.lock()操作，在析构函数中调用mutex.unlock()操作。
	借助std::lock_guard来管理mutex可以避免手动加锁时忘记释放锁的情况
- *使用了锁也并不是万无一失*
	即使对操作共享数据的每个成员函数都加锁了，也可能产生race conditions
	如何产生：
		当传递共享数据的指针或者引用到**锁的作用域之外**时，其他线程便可以不经过锁来操作共享数据。
	如何避免：
		1. 成员函数不要用共享数据的指针或者引用作为返回值
		2. 在成员函数内部不要将共享数据的指针或者引用传递给**其他函数**，因为其他函数可能会将共享数据暴露出去，使得其他线程可以轻易访问。
- *即使很好地使用了锁，也可能由于接口设计的不好导致race conditions*
	- 每一个成员函数都良好地使用了锁，因此若多个线程同时调用同一个函数，不会出现问题。
	- 但是若多个线程同时调用多个不同的接口函数，若不同的接口互相影响，则线程执行的顺序不同，程序运行的结果可能不同。
	![[Pasted image 20220416115420.png]]
	- 如上图代码段所示：如果是单线程执行，不会有问题；如果是多线程执行，可能产生race conditions，例如另一个线程在1之后2之前执行了s.pop()操作，导致s为空了，则2处的s.top()操作会出问题。
	- 栈s的内部状态已经被锁保护好了，但是无法保证外部调用不同接口时产生的race conditions。
	- 出现问题的原因可能是因为锁的粒度太小了，因此可以增大锁的粒度，比如上述代码可以改为：
```c++
stack<int> s;
std::mutex m;
std::lock_guard lg(m);  //加锁
if(!s.empty())
{
	int cons value = s.top();
	s.pop();
	do_something(value);
}
// 解锁
```
   - 锁的粒度太大也会出现问题，比如上述代码中的do_something()也处于临界区内，如果do_something本身线程安全，则没有必要给do_something也加锁；若do_somthing是非常的耗时的函数，则加锁后可能影响整个系统的运行速度
- *死锁*
	- 为了实现细粒度的控制，一个操作可能会用到多个锁，此时可能出现死锁的问题
	- 死锁产生的原因：多个线程对多个锁的申请顺序不同，每个线程都拥有一部分锁，期望获得所有的锁，所有的线程都不释放已有的锁，造成了循环等待现象
	- 避免死锁的方法：
		1. 使用std::lock()函数，std::lock函数可以同时申请多个mutex，并且采取“all or nothing”策略，即要么全部申请成功，要么全部不要。具体实现是在申请多个mutex时，若中途申请某个mutex失败，则会放弃前面已经申请成功的mutex。
		（该函数能够在一次性申请多个锁时避免死锁，但是若申请多个锁的时刻是分开的，则std::lock函数无法起作用）
		2. 没有避免死锁的银弹，只能人为地去好好设计代码
			指导原则：一个线程在另外一个线程也有可能**等待自己**的时候，不要去等待另一个线程的操作。
			1. 每个线程永远只申请一个mutex，当需要申请多个mutex时，聚合到一个时刻用std::lock()函数同时申请。
			2. 规定线程申请锁的顺序：每个线程申请多个锁时使用相同的顺序。
			3. 使用**层级锁**自动规定线程申请锁的顺序
				- 每个锁都有一个权值weight，weight大的是高层代码，weight小的是低层代码。一个线程申请下个锁时，其current weight必须大于要申请的锁的weight
				- 层级锁不是c++标准库里的实现，但是可以自己简单地实现
				- 实现自己的锁时只要定义好lock(),unlock()和try_lock()三个函数，仍然可以使用std::lock_gurad()函数来管理自定义锁
	- 死锁不仅会出现在显式地使用mutex时，只要线程间有循环等待的情况，都会出现，因此上述guidelines可以扩展到更广的范围

- *使用std::unique_lock，（相比于std::lock_guard**更为灵活**的使用锁的方式)*
	std::unique_lock更为灵活
	1. std::unique_lock在构造时不用必须获得锁。
		使用std::defer_lock可以使得在调用lock()时才真正的拥有锁，减少临界区。
		![[Pasted image 20220418120032.png]]
	2. std::unique_lock相比std::lock_guard内部多了一个**标志变量**，用来标识std::unique_lock对象是否已经拥有了锁。（因此也多了存储、管理标志变量的开销）
	3. std::unique_lock和std::unique_ptr一样都只具有移动语义。即std::unique_lock可以将一个锁的所有权转移到另一个std::unique_lock
```c++
std::unique_lock<std::mutex> get_lock()
{
	extern std::mutex some_mutex;
	std::unique_lock<std::mutex> lk(some_mutex);
	prepare_data();
	return lk;
}
void process_data()
{
	std::unique_lock<std::mutex> lk(get_lock());
	do_something();
}
```
   如上述代码所示：在get_lock()函数内的mutex可以**转移**到上层调用的函数process_data接着使用。
 4. std::unique_ptr可以在析构函数调用之前释放锁，更加灵活,可以用来减少临界区的大小，避免性能瓶颈。 
 
- *合理调整锁的粒度,只在必须加锁的地方加锁。*
	std::unique_lock有lock()和unlock()成员函数。如下代码所示，process函数不需要加锁，可以先调用unlock()释放锁。
	![[Pasted image 20220418143854.png]]

### 其他保护共享数据的措施
#### 有时共享数据只需要在初始化时被保护，初始化完成后，共享数据是read-only的
- 使用std::once_flag和std::call_once来做初始化操作。
- 各个版本初始化代码的演进：
  1. 单线程版
```c++
std::shared_ptr<some_resource> resource_ptr;
void foo()
{
	if(!resource_ptr){
		resource_ptr.reset(new some_resource);
	}
	resource_ptr->do_something();
}
```
   不加锁，在多线程时,new some_resource可能被执行多次，产生多个资源对象。
  2. 使用mutex简单加锁
```c++
std::shared_ptr<some_resource> resource_ptr;
std::mutex resource_mutex;
void foo()
{
	std::unique_lock<std::mutex> lk(resource_mutex);
	if(!resource_ptr)
	{
		resource_ptr.reset(new some_resource);
	}
	lk.unlock();
	resource_ptr->do_something();
}
```
  简单地使用mutex时，多个线程可能会**在判断resource_ptr是否存在时**阻塞在锁上，这会带来性能开销。
  3. double checked  locking
```c++
void undefined_behaviour_with_double_checked_locking()
{
	if(!resource_ptr)   //不加锁，其他线程访问资源时不用等待
	{
		std::lock_guard<std::mutex> lk(resource_mutex);
		// 初始化时再检查一遍，防止当前线程加锁的间隙，别的线程已经完成了初始化
		if(!resource_ptr)
		{
			resource_ptr.reset(new some_resource);
		}
	}
	resource_ptr->do_something();
}
```
   仍然有潜在的race conditions，因为resource_ptr是指针对象，指向某个资源，resource_ptr被构造完成时，其指向的资源对象未必构造完成。因此别的线程有可能使用**未构造完全的资源对象**
  4. 使用std::once_flag和std::call_once
   相比于使用mutex开销更小，且不会有race conditions
```c++
std::shared_ptr<some_resource> resource_ptr;
std::once_flag resource_flag;
void init_resource()
{
	resource_ptr.reset(new some_resource);
}
void foo()
{
	// call_once检查once_flag标志，保证传给他的函数只调用一次
	std::call_once(resource_flag,init_resource);
	// 其他线程就不会调用init_resource函数了
	resource_ptr->do_something();
}
```

#### 读多写少的场景可以使用读写锁
- 读多写少的场景时，大部分时间线程都只读数据，因此每次读数据时都去等待锁非常耗时，但是又不能不加锁，因为写操作虽然少，但是总会发生。
- 这种情况下可以使用读写锁。
- 读写锁的特点：
	读是共享的，多个线程可以同时拥有读的权限；写是独占的，一个时刻只有一个线程可以拥有写的权限。
	当有线程拥有读的权限时，某个想要修改共享数据的线程必须等所有线程释放读的权限后才能去获取写的权限。
	c++标准库还没有读写锁的实现，可以使用boost::shared_mutex和boost::shared_lock
#### 可重入锁
- std::mutex只允许一个线程lock()一次，lock()后要使用unlock()释放；如果某个线程lock()多次，会带来未定义行为
- 有时一个线程需要调用lock()多次,此时可以用std::recursive_mutex
- 往往是引入了不恰当的设计才会需要使用std::recurisive_mutex