
## 在线程间共享数据的问题
- 如果共享数据是read-only的，那么不存在问题
- 出现问题只发生在有线程想要修改共享数据的时候
- 出现问题时往往会破坏"一致性"(例如多线程同时修改一个共享的双向链表时，可能会破坏链表的结构，这就是破坏了一致性),会带来未定义的行为甚至程序崩溃
### Race conditions:
- 产生的原因：
	程序运行的结果和多个线程执行的顺序有关
- 性质：
	有些竞争条件是良性的，不会破坏一致性
	真正需要关注的是恶性的会破坏程序一致性的竞争条件
	可能造成未定义的行为
- 产生的时机
	竞争条件出现在某个线程**修改**某个数据时，由于cpu执行非常快速，出现竞争条件的时间窗口很小。
	只有恰好同时多个线程在时间窗口内修改了数据时，才可能会产生竞争条件
	竞争条件产生的bug往往是很难复现的
- 解决恶性race conditions的方法
 1. 对共享数据添加保护机制
	 比如锁，保证每次只能由一个线程处于修改共享数据的状态
 2. 修改数据结构的设计，使得每次修改数据都是原子操作，不同线程的执行顺序不会破坏一致性（无锁编程）
 3. 使用事务机制（类似于数据库中事务的处理）
	 事务操作每次将修改操作放到一个transaction log，然后一次性commit。commit时比较数据的状态是否一致。

### 在C++中使用锁保护共享变量
- *c++提供的锁：*
	**std::mutex**
	应该使用std::lock_guard来使用锁保护共享变量。std::lock_guard是RAII思想的实现，在构造函数中调用mutex.lock()操作，在析构函数中调用mutex.unlock()操作。
	借助std::lock_guard来管理mutex可以避免手动加锁时忘记释放锁的情况
- *使用了锁也并不是万无一失*
	即使对操作共享数据的每个成员函数都加锁了，也可能产生race conditions
	如何产生：
		当传递共享数据的指针或者引用到**锁的作用域之外**时，其他线程便可以不经过锁来操作共享数据。
	如何避免：
		1. 成员函数不要用共享数据的指针或者引用作为返回值
		2. 在成员函数内部不要将共享数据的指针或者引用传递给**其他函数**，因为其他函数可能会将共享数据暴露出去，使得其他线程可以轻易访问。
- *即使很好地使用了锁，也可能由于接口设计的不好导致race conditions*
	- 每一个成员函数都良好地使用了锁，因此若多个线程同时调用同一个函数，不会出现问题。
	- 但是若多个线程同时调用多个不同的接口函数，若不同的接口互相影响，则线程执行的顺序不同，程序运行的结果可能不同。
	![[Pasted image 20220416115420.png]]
	- 如上图代码段所示：如果是单线程执行，不会有问题；如果是多线程执行，可能产生race conditions，例如另一个线程在1之后2之前执行了s.pop()操作，导致s为空了，则2处的s.top()操作会出问题。
	- 栈s的内部状态已经被锁保护好了，但是无法保证外部调用不同接口时产生的race conditions。
	- 出现问题的原因可能是因为锁的粒度太小了，因此可以增大锁的粒度，比如上述代码可以改为：
```c++
stack<int> s;
std::mutex m;
std::lock_guard lg(m);  //加锁
if(!s.empty())
{
	int cons value = s.top();
	s.pop();
	do_something(value);
}
// 解锁
```
   - 锁的粒度太大也会出现问题，比如上述代码中的do_something()也处于临界区内，如果do_something本身线程安全，则没有必要给do_something也加锁；若do_somthing是非常的耗时的函数，则加锁后可能影响整个系统的运行速度
- *死锁*
	- 为了实现细粒度的控制，一个操作可能会用到多个锁，此时可能出现死锁的问题
	- 死锁产生的原因：多个线程对多个锁的申请顺序不同，每个线程都拥有一部分锁，期望获得所有的锁，所有的线程都不释放已有的锁，造成了循环等待现象
	- 避免死锁的方法：
		1. 使用std::lock()函数，std::lock函数可以同时申请多个mutex，并且采取“all or nothing”策略，即要么全部申请成功，要么全部不要。具体实现是在申请多个mutex时，若中途申请某个mutex失败，则会放弃前面已经申请成功的mutex。
		（该函数能够在一次性申请多个锁时避免死锁，但是若申请多个锁的时刻是分开的，则std::lock函数无法起作用）
		2. 没有避免死锁的银弹，只能人为地去好好设计代码
			指导原则：一个线程在另外一个线程也有可能**等待自己**的时候，不要去等待另一个线程的操作。
			1. 每个线程永远只申请一个mutex，当需要申请多个mutex时，聚合到一个时刻用std::lock()函数同时申请。
			2. 规定线程申请锁的顺序：每个线程申请多个锁时使用相同的顺序。
			3. 使用**层级锁**自动规定线程申请锁的顺序
				- 每个锁都有一个权值weight，weight大的是高层代码，weight小的是低层代码。一个线程申请下个锁时，其current weight必须大于要申请的锁的weight
				- 层级锁不是c++标准库里的实现，但是可以自己简单地实现
				- 实现自己的锁时只要定义好lock(),unlock()和try_lock()三个函数，仍然可以使用std::lock_gurad()函数来管理自定义锁
	- 死锁不仅会出现在显式地使用mutex时，只要线程间有循环等待的情况，都会出现，因此上述guidelines可以扩展到更广的范围

- 使用std::unique_lock，（相比于std::lock_guard**更为灵活**的使用锁的方式)
	std::unique_lock更为灵活
	1. std::unique_lock在构造时不用必须获得锁。
		使用std::defer_lock可以使得在调用lock()时才真正的拥有锁，减少临界区。
		![[Pasted image 20220418120032.png]]
	2. std::unique_lock相比std::lock_guard内部多了一个**标志变量**，用来标识std::unique_lock对象是否已经拥有了锁。（因此也多了存储、管理标志变量的开销）
	3. std::unique_lock和std::unique_ptr一样都只具有移动语义。即std::unique_lock可以将一个锁的所有权转移到另一个std::unique_lock
```c++
std::unique_lock<std::mutex> get_lock()
{
	extern std::mutex some_mutex;
	std::unique_lock<std::mutex> lk(some_mutex);
	prepare_data();
	return lk;
}
void process_data()
{
	std::unique_lock<std::mutex> lk(get_lock());
	do_something();
}
```
   如上述代码所示：在get_lock()函数内的mutex可以**转移**到上层调用的函数process_data接着使用。
 4. std::unique_ptr可以在析构函数调用之前释放锁，更加灵活,可以用来减少临界区的大小，避免性能瓶颈。 