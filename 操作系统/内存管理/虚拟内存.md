# 虚拟内存
## 概念
虚拟内存（virtual memory）是对主存的一种抽象概念，它为每个进程提供了大的、一致的和私有的地址空间

## 提供的三个重要能力
1. 把主存当作磁盘的高速缓冲设备，主存里只存放当前进程所需的数据，根据需要在主存和磁盘间交换数据
2. 为每个进程提供了一致的地址空间，简化了内存管理
3. 保证了进程之间的隔离，一个进程的地址空间不被其他进程破坏


# 从两个方面理解虚拟内存
## 虚拟内存作为缓存的工具
从主存作为磁盘的缓存的角度上来看：
1. 主存的存取速度远远大于磁盘的存取速度（磁盘要比DRAM 慢大约100 000 多倍），因此读取磁盘上的数据时，都是先把磁盘上的数据读到内存
2. 主存的空间大小远远小于磁盘空间的大小，因此磁盘上的内容不可能完全加载到主存上去

**虚拟内存为什么要以页为单位**
	虚拟内存的最小单位是页（页的大小通常是4KB~2MB），类似地，物理内存被划分为物理页（页帧）
	这是因为磁盘是一个块设备，从磁盘的一个扇区读取第一个字节的时间开销比起**读这个扇区中连续的字节**要慢大约100 000 倍
	因此内存以页为单位去缓存磁盘的数据，页的大小通常大于等于磁盘IO每次读一块的大小

**虚拟内存在内存作为磁盘缓存时起了什么作用**
还是因为主存的空间远远小于磁盘空间的问题，系统首先并不真正将磁盘上所有数据加载到物理内存，而是建立虚拟内存的页到磁盘上的块的**映射关系**。
![[Pasted image 20220610154541.png]]
如上图所示，在任意时刻，虚拟页面的集合都分为三个不相交的子集：
- 未分配的：VM 系统还未分配(或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
- 缓存的：当前已缓存在物理内存中的已分配页。
- 未缓存的：未缓存在物理内存中的已分配页。

虚拟内存必须知道上述三种子集的情况，因此需要一个数据结构存放这些信息，这就是页表

### 页表
页表由页表项组成，每个页表项大小固定
在只考虑虚拟内存的缓存功能时，页表项至少有以下内容：
	1. 页表项会存放一个有效位，标志该页是否已经从磁盘加载到了物理内存 
	2. 页表项的有效位后面存放的是物理页号或者磁盘地址（MMU做虚拟地址到物理地址的翻译时要用到）
操作系统要负责维护页表的内容；当物理内存满了，负责页面置换，将物理内存的某页换出到磁盘以及从磁盘中加载新页到物理内存

![[Pasted image 20220610155326.png]]
**页命中的流程**：
	1. MMU作为一个地址翻译单元使用传入的虚拟地址作为索引，从页表中找到页表项（PTE)
	2. 查看PTE的有效位是否为1，如果*为1*，说明页命中了，该页正缓存在物理内存中，然后就使用页表项中存放的物理地址来访问物理页面

**缺页时的流程**：
	在DRAM中缓存不命中即为缺页（page fault）
	1. MMU作为一个地址翻译单元使用传入的虚拟地址作为索引，从页表中找到页表项（PTE)
	2. 查看PTE的有效位是否为1，如果*不为1*，说明该页没有缓存在物理内存中，触发缺页异常并调用缺页异常处理程序
	缺页中断：
	1. 如果物理内存还有空间，则就会根据PTE的磁盘地址，读取磁盘块的内容到物理内存的空闲页中
	2. 如果物理内存没有空间，则要执行页面置换算法，从物理内存中换出一个页（如果物理内存的内容有被修改，则要复制回磁盘），然后将磁盘的对应块换入
	从缺页中断处理程序返回：
		重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重新发送到MMU中，因为该页已经在物理内存中了，接下来就是正常的*页命中*的流程

### 局部性原理使得虚拟页表工作效率很高
- 整个程序运行过程中引用的不同页面的总数可能超过物理内存总的大小
- 局部性原理保证了任意时刻，程序趋向于在一个较小的活动页面（active page)集合上工作，这个集合叫做工作集(working set)
- 程序启动时就将工作集页面调度到内存中，接下来对工作集内存页面的访问将导致命中，不需要从磁盘中去读
- 如果程序的局部性不好，那么很可能频繁地出现页面换入换出的现象（也叫做*抖动*）

## 虚拟内存作为内存管理的工具
操作系统为每个进程都提供了独立的页表，即每个进程都有自己独立的虚拟内存空间
多个虚拟页面可以共享同一个物理页面
![[Pasted image 20220610164541.png]]

### 按需页面调度和独立的虚拟地址空间带来的好处
**简化链接**
	1. 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不用考虑代码和数据实际放在物理内存的何处
	2. 这样的一致性简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，而不用管每个可执行文件在物理内存上是怎么放的

**简化加载**
	1. 虚拟内存使得容易向内存中加载可执行文件和共享对象
	2. 要把目标文件中.text 和.data 节加载到一个新创建的进程中，Linux 加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的）， 将页表条目指向*目标文件*中适当的位置
	3. 在每个页被初次引用时，才会真正地将数据页从磁盘调入物理内存
	
**简化共享**
	1. 每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。在这种情况中，操作系统创建页表，将相应的虚拟页映射到不连续的物理页面。
	2. 但是还是会有进程间共享内存的需求，比如多个进程都需要调用相同的操作系统内核代码，都需要使用相同的C库函数。通过将不同进程的虚拟页映射到相同的物理页面，从而安排多个进程共享这部分内存
	
**简化内存分配**
虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如调用malloc 的结果）， 操作系统分配一个适当数字（例如k个连续的虚拟内存页面），并且将它们映射到物理内存中任意k个物理页面（这k个物理页面不需要是连续的，可以随机分散在物理）

## 虚拟内存作为内存保护的工具
操作系统需要提供对内存的保护控制机制
	用户程序不能修改代码段等只读数据
	用户态不能访问内核态的任何代码和数据结构
	某个进程不能访问其他进程的私有内存空间
	
![[Pasted image 20220610172053.png]]
可以从地址翻译机制中扩展出内存保护和访问控制机制
如上图所示，每个页表项新增几个许可位
	SUP：表示进程是否运行在内核态才能访问该页面
	READ：表示是否有权力读该页面
	WRITE：表示是否有权利写该页面

```text
如果一条指令违反了这些许可条件，那么CPU 就触发一个一般保护故障，将控制传
递给一个内核中的异常处理程序。Linux shell —般将这种异常报告为“段错误(segmentation fault)
```


# 地址翻译
## 地址翻译的概念
![[Pasted image 20220610173656.png]]

## 地址翻译的流程
- MMU是地址翻译的硬件
- 页表是MMU进行地址翻译需要用到的数据结构
- 虚拟地址是从页表中定位页表项的索引
	地址长度为n的虚拟地址分为两部分，0~p-1是单个页面内的偏移量，和物理页中的偏移量一一对应；p~n-1是虚拟页号，作为到页表中定位页表项的索引
	
![[Pasted image 20220610173731.png]]

**当页面命中时，CPU硬件执行的步骤**
![[Pasted image 20220611102003.png]]
分为两步，第一是得到页表项，第二是根据页表项构造物理地址
第1 步：处理器生成一个虚拟地址，并把它传送给MMU
第2 步：MMU 生成PTE 地址，并从高速缓存/主存请求得到它。
第3 步：高速缓存/主存向MMU 返回PTE
第4 步：MMU 构造物理地址，并把它传送给高速缓存/主存。
第5 步：高速缓存/主存返回所请求的数据字给处理器

**当页面未命中时，cpu硬件执行的步骤**
![[Pasted image 20220611102328.png]]
第1 步：处理器生成一个虚拟地址，并把它传送给MMU
第2 步：MMU 生成PTE 地址，并从高速缓存/主存请求得到它。
第3 步：高速缓存/主存向MMU 返回PTE
*前三步和页面命中的步骤相同*
第4步：PTE中的有效位是0，触发缺页异常，CPU开始执行操作系统的缺页异常处理程序
第5步：从物理内存中选定牺牲页，如果该页被修改过，则复制内容到磁盘
第6步：从磁盘中换出新页到物理内存，并更新内存中的PTE
第7步：缺页处理程序回到原来的指令，再从第一步开始执行。CPU 将引起缺
页的虚拟地址重新发送给MMUÿ 因为虚拟页面现在缓存在物理内存中，所以就会命中

## 使用TLB加速地址翻译
TLB(Translation Lookaside Buffer)：翻译后备缓冲器
- 是一个小的、虚拟寻址的缓存
- 是MMU中的硬件
- 每一行都保存一个PTE
- 使用虚拟地址作为索引来访问TLB
	![[Pasted image 20220611103655.png]]

**TLB命中时地址翻译的步骤**：
![[Pasted image 20220611103549.png]]
1. CPU产生一个虚拟地址
2. MMU使用虚拟地址作为TLB索引获取PTE
3. MMU 构造物理地址，并把它传送给高速缓存/主存
4. 高速缓存/主存返回所请求的数据字给处理器

可见相比没有TLB时的步骤，可以直接从TLB中得到PTE，不用从高速缓存/内存中去取PTE，大大加快了地址翻译的速度

当TLB不命中时，MMU必须从高速缓存L1中取出PTE。并且把新取出的PTE放到TLB中，如果TLB已满，则会覆盖一个TLB表项


## 多级页表
上面的地址翻译流程都假定只使用了单级页表，单级页表的PTE里存放的就是物理内存页面的物理页号

单级页表的问题
1. 页表过大
	例如32位地址空间下，页面大小为4KB，此时共有2^32/4KB = 2^20个页表项，如果每个页表项的大小是4B，那么页表的大小就是2^20 x 4B = 4MB；每个进程都有自己的页表，因此每个进程都需要4MB的页表驻留在内存中
	如果是64位地址空间，则情况更加复杂

使用**多级页表**来解决单级页表驻留内存过大的问题
以二级页表为例：
![[Pasted image 20220611105811.png]]
1. 一级页表里的PTE存放的是二级页表的基址
2. 二级页表里的PTE和单级页表里存的PTE相同，都负责映射一个4KB的虚拟内存页面

一级页表和二级页表的大小都是4KB，即一个页面的大小。
*从两个方面减少了内存的需求*：
1. 如果一级页表的某个表项PTE是空的，那么相应的二级页表就不会存在；这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB 的虚拟地址空间的大部分都会是未分配的
2. 只有一级页表才需要常驻在内存中，虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中

**因为TLB能够缓存多级页表的PTE，因此多级页表的翻译和单级页表的翻译相比不会慢很多**


