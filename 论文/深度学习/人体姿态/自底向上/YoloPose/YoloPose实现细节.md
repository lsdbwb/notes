# COCO数据集labels
YoloPose的数据集的lables是人体框+人体骨骼关键点


标签targets的shape：
` nl(当前batch所有图片中人的个数) x 40(6 + 2 x 17 )`
6是目标检测用到的bbox信息和分类信息，后面是关键点信息（17个关键点以及坐标）

# 模型输出结果
可见是四个head，每个head包括Box和Keypoints
![[Pasted image 20220706114638.png]]

以输入图片大小为960的Yolov5m6_pose_960模型为例，模型输出的结果如下图所示：
![[YoloPose实现细节 2022-07-06 11.55.53.excalidraw]]

- 一张输入的图片 ：3 x 960 x 960
- 两个输出：
1. train_out(该输出后续用于计算损失函数) : 四个分支,形状如上图所示
2. out（该输出是推理时的输出，后续使用NMS后处理获得模型推理结果） : 57375 x 57
	 `57375 = 3 x(120 x 120 + 60 x 60 + 30 x 30 + 15 x 15)` 
	
	`57 = 4 + 1 + 1 + 17 x 3`
    4 ： BBOX
    1 ：BBOX置信度
    1：分类置信度
    17 x 3 ： 17个关键点 : (x, y, conf)

# 训练时计算损失函数
损失函数公式[[YoloPose论文解析#损失函数]]



# 后处理NMS
就是正常的目标检测的NMS的流程。每个BBOX内的人体关键点信息在nms时没有作用