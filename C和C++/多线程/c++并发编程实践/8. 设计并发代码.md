# 指导思想
- 设计完备多线程程序不仅仅是掌握锁、条件变量、原子操作等基本操作就够了，还需要从更高层掌握多线程程序的设计思想
- 不仅要考虑线程的数量，线程间的任务分配等上层的设计，也要考虑底层的影响程序性能的细节

# 在线程间调配任务的技术
- 确保使用多线程为你的程序带来的收益（并发带来的性能提升）大于带来的损失（代码复杂度，潜在的race condiiton）
- 确定一个工作可以划分为多个互不相关的子任务
- 每个子任务选择**专门的线程**来完成，每个子任务使用的线程数量可以自行分配
- 是否需要专门的线程来做所有子任务的统筹安排
## 在线程间划分数据的方法
### 在程序开始之前就把数据划分好
- 如下图所示，在程序开始执行之前，将整块数据划分为多个chunk，每个chunk分给一个线程，线程间互不干扰
![[Pasted image 20220506113239.png]]
- 在所有的线程处理完后，可能需要聚合所有线程的结果，做一次reduce操作
- 要求：数据能够被清晰地划分且数据间没有关联，最终所需的结果能够由多个线程处理的结果聚合得到
### 运行时递归地划分数据
- 如下图所示，无法在程序运行开始前就把数据划分好，因为数据的划分和程序的运行状态有关
- 递归划分的每一部分的数据都是独立的，都可以用一个线程来处理
- 递归的深度过深时，使用的线程过多会影响性能，因此需要限制线程使用的数量
![[Pasted image 20220506114111.png]]
- 当限制了线程数量时，有些数据暂时得不到处理时可以先放到栈中，工作线程空闲后再去栈顶取数据处理

## 通过任务类型划分工作
- 在线程间划分数据的方法依赖于每个线程都完成**同样的工作**
- 实际上每个线程完成的任务可能是不同的
- 将整个系统划分为多个独立的小任务，每个任务指定一个线程来执行。线程间相对独立，只需要很少的交互
- 通过任务类型来划分，业务线程负责业务，系统后台线程负责系统的运行，监听线程负责监控系统的状态。（这些线程之间都会有交互，如果两个线程交互过于频繁，通信量太大，则要考虑任务划分的方法是否合适）

## 将一长串的任务划分为多个阶段
- 如果一个任务很长，可以划分为多个阶段，且每个阶段用到的数据是独立的
- 可以使用流水线模型(pipelines)
- 每个阶段都用一个或一组线程来完成，线程之间使用管道或者任务队列通信。前一个线程完成该阶段的事情后，将处理的结果放到队列，下一个线程从队列中取出数据接着处理

# 影响并发代码性能的因素
设计出的并发程序应该相比于单线程下有性能提升，不然毫无意义
## 处理器核心的数量
- 开发环境和实际部署生产环境的CPU数量，每个CPU的核心数量是不同的
- 因此需要根据实际环境设置合适的线程数量
- std::thread::hardware_concurrency()可以返回当前系统支持的最大线程数量。（只是一个提示，某些情况下不可信）
## data contention和cache ping-pong
在使用的线程数和CPU数量多了之后，多个处理器访问**共享数据**的可能性增大
- 在多个处理器**同时读**内存中的同一块数据时没有问题，每个处理器的缓存都有该内存数据的一份拷贝
- 如果有某个处理器要修改这个数据，则需要把缓存中修改过后的数据同步给其他处理器。（即缓存一致性，保证缓存一致性的cpu指令会很耗时）
- high data contention
	如果某个共享数据同时有多个处理器要访问并修改，其他处理器必须等待某个处理器修改该数据并执行完缓存同步操作后，才能继续执行
- cache ping-pong
	即在上述 high data contention的情况下，不停执行缓存同步的行为（缓存在多个处理器间不停同步）
- 使用mutex时，mutex就可以认为是共享数据，high data contention情况下也会出现上述问题
	mutex规定的是线程间在**操作系统层面**的同步（而不是处理器层面），如果某个线程在等待mutex，操作系统可以调度其他线程来使用CPU。但mutex也是共享数据，在多处理器对其进行同时访问操作时就会出现缓存一致性的问题

## false sharing
- false sharing指的是共享一个cache line里的不同数据

- 在多处理器同时访问一个内存位置的共享数据时要进行**cache**的同步，在high contention下会造成cache ping-pong问题
- 最好的解决方法就是尽量不使用共享数据

- cpu以cache-line为单位读取内存中的数据到缓存，并且以cache-line为单位在缓存间进行数据同步，通常cache-line的大小为32或者64bytes
- 即使某个内存位置某时刻仅仅被一个线程访问，仍然可能出现cache ping-pong问题，即多个线程访问同一个cache line不同内存位置的数据

- 缓解false sharing问题 ： 设计数据结构，使得每个线程尽量访问邻近内存的数据

## 多线程下任务调度的问题
1. 如果某个线程访问的数据都很分散，则会需要多个不同的cache line，并且每个cache line可能都只包含一部分该线程需要的数据。这会带来cache空间的浪费，同时增加多线程下false sharing的概率
2. 如果每个线程访问的数据都很集中，这能够缓解false sharing的问题。但是在线程数多于cpu核心数量，需要频繁进行线程切换的情况下，可能会造成性能问题（线程频繁切换，缓存就需要不停地换入换出）
3. 在有多个线程时，操作系统为每个线程划分时间片，某个线程可能上一个时间片在cpu的A核心，下一个时间片被调度到cpu的B核心，相应地缓存也要从A核心迁移到B核心，这也是产生性能损耗的地方
4. 因此要避免启动太多的线程，以免造成过大的上下文切换和缓存更新的开销

# 设计多线程下性能良好的数据结构
指导原则
- 尽量使单线程的数据存放在内存中相邻的位置
- 多线程下，尽量使每个线程的数据存放在内存中的相隔较远的位置，避免false sharing

# 设计并发代码时额外需要考虑的事情
## 并行算法的异常安全问题
- 多线程下更容易产生异常安全问题
- 在多线程下处理异常安全问题更加复杂和困难。在单线程程序中，某个函数抛出异常后可以回到调用者来处理；在多线程下，可能在某个线程的函数中抛出异常，调用者在另外一个线程，调用栈不一样，无法将异常传回调用者处理。
- 如果不对子线程调用的函数做任何异常安全处理，则子线程异常发生时，std::thread对象会被析构，std::terminate会被调用并终止整个程序
## 可扩展性和阿姆达尔定律
- 多线程下，可扩展性指的是系统的性能表现应该随着CPU核数的增加而增强，理想情况下应该是线性扩展的
- 线程并不是每时每刻都在占用cpu做计算，有可能会等待IO，等待其他线程，等待锁、信号量等等。在cpu空闲的时候可以调用其他的线程来做计算，让cpu始终保持忙碌状态
- 一个程序不是所有部分都可以并行的，程序可以划分为可并行的部分和只能串行的部分。可并行的部分占比越大，可能获得的性能加速越多
- 阿姆达尔定律就是用来描述程序可并行的部分的大小对系统整体性能的影响

	fs表示串行部分占程序的比例，N表示处理器的核心数。当fs为0时，表示整个程序都可以并行化，可以获得N倍的加速；fs为1时，表示整个程序都是串行的，系统只能单核运行

## 为线程赋予职责
- IO线程专门负责IO，处理线程专门负责处理任务，互不干扰

